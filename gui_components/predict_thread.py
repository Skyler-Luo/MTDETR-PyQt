"""
é¢„æµ‹çº¿ç¨‹æ¨¡å—ï¼ˆé‡æ„ç‰ˆï¼‰
èŒè´£ï¼šç®¡ç†å¼‚æ­¥é¢„æµ‹ä»»åŠ¡ï¼Œé¿å…UIå†»ç»“
"""

import os
import cv2
import numpy as np
from pathlib import Path
from PyQt5.QtCore import QThread, pyqtSignal

from utils import (
    DetectionRenderer, BannerRenderer, TrafficLightAnalyzer, DrivableAreaAnalyzer,
    YOLO_PERSON_CLASS_ID, YOLO_TRAFFIC_LIGHT_CLASS_ID, YOLO_OTHER_CLASS_ID,
    YOLO_PERSON_ORIGINAL_ID, YOLO_TRAFFIC_LIGHT_ORIGINAL_ID
)


class PredictThread(QThread):
    """
    é¢„æµ‹çº¿ç¨‹ - å¼‚æ­¥æ‰§è¡Œæ¨¡å‹æ¨ç†
    
    Signals:
        finished: (success: bool, message: str) - é¢„æµ‹å®Œæˆä¿¡å·
        progress: (message: str) - è¿›åº¦æ›´æ–°ä¿¡å·
        progress_percent: (percent: int) - è¿›åº¦ç™¾åˆ†æ¯”ä¿¡å· (0-100)
        log: (message: str) - æ—¥å¿—è¾“å‡ºä¿¡å·
    """
    
    finished = pyqtSignal(bool, str)
    progress = pyqtSignal(str)
    progress_percent = pyqtSignal(int)  # æ–°å¢ï¼šè¿›åº¦ç™¾åˆ†æ¯”ä¿¡å·
    log = pyqtSignal(str)
    
    def __init__(self, model, source, params, person_model=None):
        """
        åˆå§‹åŒ–é¢„æµ‹çº¿ç¨‹
        
        Args:
            model: ä¸»æ¨¡å‹ï¼ˆMTDETRï¼‰
            source: æ•°æ®æºè·¯å¾„
            params: é¢„æµ‹å‚æ•°å­—å…¸
            person_model: å¯é€‰çš„è¡Œäººæ£€æµ‹æ¨¡å‹ï¼ˆYOLOv10nï¼‰
        """
        super().__init__()
        self.model = model
        self.person_model = person_model
        self.source = source
        self.params = params
        
        # åˆ›å»ºæ¸²æŸ“å™¨
        self.renderer = DetectionRenderer()
    
    def reset_model_config(self):
        """é‡ç½®æ¨¡å‹é…ç½®ï¼Œç¡®ä¿æ–°å‚æ•°ç”Ÿæ•ˆ"""
        if hasattr(self.model, 'predictor') and self.model.predictor is not None:
            self.model.predictor = None
        
        # æ¸…ç† overrides ä¸­çš„æ˜¾ç¤ºç›¸å…³é…ç½®
        if hasattr(self.model, 'overrides'):
            display_keys = ['show_boxes', 'show_labels', 'show_conf', 
                          'show', 'save', 'line_width']
            for key in display_keys:
                self.model.overrides.pop(key, None)
    
    def run(self):
        """æ‰§è¡Œé¢„æµ‹ä»»åŠ¡"""
        try:
            self.progress.emit("æ­£åœ¨è¿›è¡Œé¢„æµ‹...")
            
            # æ‰“å°å‚æ•°ä»¥ä¾¿è°ƒè¯•
            self.log.emit(f"[é¢„æµ‹å‚æ•°] show_boxes={self.params['show_boxes']}, "
                         f"show_labels={self.params['show_labels']}, "
                         f"show_conf={self.params['show_conf']}, "
                         f"enable_person_detection={self.params.get('enable_person_detection', False)}")
            
            # é‡ç½®æ¨¡å‹é…ç½®
            self.reset_model_config()
            
            # æ ¹æ®æ˜¯å¦å¯ç”¨è¡Œäººæ£€æµ‹é€‰æ‹©é¢„æµ‹æ¨¡å¼
            if self.person_model and self.params.get('enable_person_detection', False):
                self._dual_model_predict()
            else:
                self._single_model_predict()
            
            # å®Œæˆ
            self.progress.emit("é¢„æµ‹å®Œæˆï¼")
            output_path = os.path.join(self.params['project'], self.params['name'])
            self.finished.emit(True, output_path)
            
        except Exception as e:
            import traceback
            error_msg = traceback.format_exc()
            self.log.emit(f"[é”™è¯¯] {error_msg}")
            self.finished.emit(False, str(e))
    
    def _single_model_predict(self):
        """å•æ¨¡å‹é¢„æµ‹æµç¨‹"""
        # ä½¿ç”¨ hook æ•è·åˆ†å‰²æ©ç 
        from ultralytics.models.mtdetr.predict import MTDETRPredictor
        
        # åˆ›å»º predictor
        if not hasattr(self.model, 'predictor') or self.model.predictor is None:
            self.model.predictor = MTDETRPredictor(overrides={
                'imgsz': self.params['imgsz'],
                'device': self.params['device'],
                'mask_threshold': self.params['mask_threshold']
            })
            self.model.predictor.setup_model(model=self.model.model)
        
        # è®¾ç½®å‚æ•°
        self.model.predictor.args.imgsz = self.params['imgsz']
        self.model.predictor.args.device = self.params['device']
        self.model.predictor.args.mask_threshold = self.params['mask_threshold']
        
        # æ•è·åˆ†å‰²æ©ç  - ä½¿ç”¨åˆ—è¡¨æ”¶é›†æ‰€æœ‰å›¾ç‰‡çš„æ©ç 
        seg_masks_list = []
        original_postprocess = self.model.predictor.postprocess
        
        def custom_postprocess(preds, img, orig_imgs):
            nonlocal seg_masks_list
            results, seg_mask = original_postprocess(preds, img, orig_imgs)
            # æ”¶é›†æ¯æ¬¡çš„æ©ç 
            if seg_mask is not None:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰¹å¤„ç†ï¼ˆå¤šå¼ å›¾ç‰‡ä¸€æ¬¡å¤„ç†ï¼‰
                if hasattr(seg_mask, 'shape') and len(seg_mask.shape) > 0:
                    # å¦‚æœæ˜¯æ‰¹å¤„ç†ï¼Œseg_mask åŒ…å«å¤šå¼ å›¾ç‰‡çš„æ©ç 
                    seg_masks_list.append(seg_mask)
                else:
                    seg_masks_list.append(seg_mask)
            return results, seg_mask
        
        self.model.predictor.postprocess = custom_postprocess
        
        try:
            results = self.model.predict(
                source=self.source,
                imgsz=self.params['imgsz'],
                device=self.params['device'],
                conf=self.params.get('conf', 0.25),  # ç½®ä¿¡åº¦é˜ˆå€¼
                mask_threshold=self.params['mask_threshold'],
                show_boxes=self.params['show_boxes'],
                show_labels=self.params['show_labels'],
                show_conf=self.params['show_conf'],
                save=False,  # å…ˆä¸ä¿å­˜ï¼Œæ‰‹åŠ¨ç»˜åˆ¶åå†ä¿å­˜
                save_txt=False,  # ç¦ç”¨ultralyticsçš„æ ‡ç­¾ä¿å­˜ï¼Œä½¿ç”¨è‡ªå®šä¹‰ä¿å­˜
                save_conf=False,
                project=self.params['project'],
                name=self.params['name'],
                exist_ok=True
            )
        finally:
            self.model.predictor.postprocess = original_postprocess
        
        self.log.emit(f"[å•æ¨¡å‹] é¢„æµ‹å®Œæˆï¼Œç»“æœæ•°é‡: {len(results)}")
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        if seg_masks_list:
            # æ£€æŸ¥æ©ç æ‰¹æ¬¡ä¿¡æ¯
            if len(seg_masks_list) > 0 and hasattr(seg_masks_list[0], 'shape'):
                self.log.emit(f"[å•æ¨¡å‹] âœ“ æˆåŠŸè·å– {len(seg_masks_list)} æ‰¹æ©ç ï¼Œç¬¬ä¸€æ‰¹å½¢çŠ¶: {seg_masks_list[0].shape}")
            else:
                self.log.emit(f"[å•æ¨¡å‹] âœ“ æˆåŠŸè·å– {len(seg_masks_list)} ä¸ªåˆ†å‰²æ©ç ")
        else:
            self.log.emit(f"[å•æ¨¡å‹] âœ— æœªè·å–åˆ°åˆ†å‰²æ©ç ")
        
        # æ‰‹åŠ¨ç»˜åˆ¶å¹¶ä¿å­˜ç»“æœ
        if self.params['save']:
            self._save_single_model_results(results, seg_masks_list)
    
    def _save_single_model_results(self, results, seg_masks_list=None):
        """ä¿å­˜å•æ¨¡å‹é¢„æµ‹ç»“æœ"""
        output_dir = Path(self.params['project']) / self.params['name']
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºlabelsç›®å½•ç”¨äºä¿å­˜æ ‡ç­¾æ–‡ä»¶
        labels_dir = output_dir / "labels"
        labels_dir.mkdir(exist_ok=True)
        
        # å¤„ç†æ©ç ï¼šå¯èƒ½æ˜¯åˆ—è¡¨å½¢å¼ï¼ˆæ¯æ¬¡è°ƒç”¨ä¸€å¼ å›¾ï¼‰æˆ–æ‰¹å¤„ç†å½¢å¼ï¼ˆä¸€æ¬¡å¤šå¼ å›¾ï¼‰
        seg_masks = None
        if seg_masks_list:
            if len(seg_masks_list) == 1:
                # å¯èƒ½æ˜¯æ‰¹å¤„ç†ï¼Œä¸€æ¬¡è¿”å›æ‰€æœ‰å›¾ç‰‡çš„æ©ç 
                seg_masks = seg_masks_list[0]
            elif len(seg_masks_list) == len(results):
                # æ¯å¼ å›¾ç‰‡å•ç‹¬è¿”å›çš„æ©ç åˆ—è¡¨
                seg_masks = seg_masks_list
            else:
                self.log.emit(f"[è­¦å‘Š] æ©ç æ•°é‡({len(seg_masks_list)})ä¸ç»“æœæ•°é‡({len(results)})ä¸åŒ¹é…")
        
        total_images = len(results)
        for i, result in enumerate(results):
            # å‘é€è¿›åº¦ç™¾åˆ†æ¯”
            progress_percent = int((i + 1) / total_images * 100)
            self.progress_percent.emit(progress_percent)
            self.progress.emit(f"æ­£åœ¨ä¿å­˜: {i+1}/{total_images}")
            img = result.orig_img.copy()
            
            # 1. ç»˜åˆ¶åˆ†å‰²æ©ç 
            if seg_masks is not None:
                try:
                    # æ„å»ºç±»åˆ«åç§°å­—å…¸
                    class_names = {}
                    if hasattr(self.model, 'names') and isinstance(self.model.names, dict):
                        class_names = self.model.names
                    
                    # æ ¹æ®æ©ç ç±»å‹æå–å½“å‰å›¾ç‰‡çš„æ©ç 
                    if isinstance(seg_masks, list) and i < len(seg_masks):
                        current_mask = seg_masks[i]
                    else:
                        # å‡è®¾æ˜¯æ‰¹å¤„ç†æ ¼å¼ï¼Œç›´æ¥ä¼ å…¥æ•´ä¸ªæ©ç 
                        current_mask = seg_masks
                    
                    # ç»˜åˆ¶æ‰€æœ‰æ©ç 
                    img = self.renderer.draw_all_segmentation_masks(
                        img, current_mask, class_names
                    )
                    self.log.emit(f"[å•æ¨¡å‹] å›¾ç‰‡ {i+1}/{len(results)} - âœ“ ç»˜åˆ¶åˆ†å‰²æ©ç æˆåŠŸ")
                except Exception as e:
                    self.log.emit(f"[å•æ¨¡å‹] å›¾ç‰‡ {i+1}/{len(results)} - âœ— ç»˜åˆ¶æ©ç å¤±è´¥: {e}")
                    import traceback
                    self.log.emit(traceback.format_exc())
            
            # 2. ç»˜åˆ¶æ£€æµ‹æ¡†å’Œæ ‡ç­¾
            if result.boxes is not None:
                for box in result.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    conf = float(box.conf[0])
                    cls_id = int(box.cls[0])
                    
                    # è·å–ç±»åˆ«åç§°
                    class_name = self.renderer.get_class_name(cls_id, result, self.model)
                    self.log.emit(f"[å•æ¨¡å‹] æ£€æµ‹: ç±»åˆ«ID={cls_id}, ç±»åˆ«åç§°='{class_name}', ç½®ä¿¡åº¦={conf:.2f}")
                    
                    # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                    img = self.renderer.draw_detection(
                        img, [x1, y1, x2, y2], cls_id, conf, class_name,
                        show_box=self.params['show_boxes'],
                        show_label=self.params['show_labels'],
                        show_conf=self.params['show_conf']
                    )
            
            # 3. ä¿å­˜å›¾åƒ
            if hasattr(result, 'path'):
                filename = Path(result.path).name
            else:
                filename = f"image_{i}.jpg"
            
            output_path = output_dir / filename
            cv2.imwrite(str(output_path), img)
            self.log.emit(f"[å•æ¨¡å‹] ä¿å­˜: {output_path}")
            
            # 4. ä¿å­˜æ ‡ç­¾æ–‡ä»¶ï¼ˆåŒ…å«ç½®ä¿¡åº¦ï¼‰
            if self.params.get('save_txt', True) and result.boxes is not None:
                label_filename = Path(filename).stem + '.txt'
                label_path = labels_dir / label_filename
                
                with open(label_path, 'w') as f:
                    for box in result.boxes:
                        xywhn = box.xywhn[0]
                        cls = int(box.cls[0])
                        conf = float(box.conf[0])
                        # ä¿å­˜æ ¼å¼: class_id x_center y_center width height confidence
                        f.write(f"{cls} {xywhn[0]} {xywhn[1]} {xywhn[2]} {xywhn[3]} {conf}\n")
                
                self.log.emit(f"[å•æ¨¡å‹] ä¿å­˜æ ‡ç­¾: {label_path}")
    
    def _dual_model_predict(self):
        """åŒæ¨¡å‹é¢„æµ‹æµç¨‹ï¼šMTDETR + YOLOv10n"""
        self.progress.emit("åŒæ¨¡å‹æ£€æµ‹ä¸­...")
        
        # è¿è¡Œ MTDETR é¢„æµ‹å¹¶æ•è·åˆ†å‰²æ©ç 
        self.log.emit("[åŒæ¨¡å‹] è¿è¡Œ MTDETR...")
        mtdetr_seg_masks_list = []
        
        from ultralytics.models.mtdetr.predict import MTDETRPredictor
        
        if not hasattr(self.model, 'predictor') or self.model.predictor is None:
            self.model.predictor = MTDETRPredictor(overrides={
                'imgsz': self.params['imgsz'],
                'device': self.params['device'],
                'mask_threshold': self.params['mask_threshold']
            })
            self.model.predictor.setup_model(model=self.model.model)
        
        # Hook postprocess to capture seg_masks
        original_postprocess = self.model.predictor.postprocess
        
        def custom_postprocess(preds, img, orig_imgs):
            nonlocal mtdetr_seg_masks_list
            results, seg_mask = original_postprocess(preds, img, orig_imgs)
            # æ”¶é›†æ¯æ¬¡çš„æ©ç 
            if seg_mask is not None:
                mtdetr_seg_masks_list.append(seg_mask)
            return results, seg_mask
        
        self.model.predictor.postprocess = custom_postprocess
        
        try:
            mtdetr_output = self.model.predict(
                source=self.source,
                imgsz=self.params['imgsz'],
                device=self.params['device'],
                conf=self.params.get('conf', 0.25),  # ç½®ä¿¡åº¦é˜ˆå€¼
                mask_threshold=self.params['mask_threshold'],
                show_labels=self.params['show_labels'],
                save=False,
                verbose=False
            )
        finally:
            self.model.predictor.postprocess = original_postprocess
        
        mtdetr_results = mtdetr_output if isinstance(mtdetr_output, list) else [mtdetr_output]
        
        # 2. è¿è¡Œ YOLOv10n è¡Œäººå’Œçº¢ç»¿ç¯æ£€æµ‹
        self.log.emit("[åŒæ¨¡å‹] è¿è¡Œ YOLOv10n...")
        # ä½¿ç”¨ç»Ÿä¸€çš„ç±»åˆ«IDå¸¸é‡
        person_results = self.person_model.predict(
            source=self.source,
            imgsz=self.params['imgsz'],
            device=self.params['device'],
            classes=[YOLO_PERSON_ORIGINAL_ID, YOLO_TRAFFIC_LIGHT_ORIGINAL_ID],
            conf=self.params.get('conf', 0.25),  # ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„ç½®ä¿¡åº¦é˜ˆå€¼
            save=False,
            verbose=False
        )
        
        # 3. åˆå¹¶å¹¶ä¿å­˜ç»“æœ
        self.progress.emit("åˆå¹¶æ£€æµ‹ç»“æœ...")
        if mtdetr_seg_masks_list:
            self.log.emit(f"[åŒæ¨¡å‹] âœ“ æˆåŠŸè·å– {len(mtdetr_seg_masks_list)} ä¸ªåˆ†å‰²æ©ç ")
        self._merge_and_save_dual_results(mtdetr_results, person_results, mtdetr_seg_masks_list)
    
    def _merge_and_save_dual_results(self, mtdetr_results, person_results, seg_masks_list=None):
        """åˆå¹¶åŒæ¨¡å‹ç»“æœå¹¶ä¿å­˜"""
        output_dir = Path(self.params['project']) / self.params['name']
        output_dir.mkdir(parents=True, exist_ok=True)
        labels_dir = output_dir / "labels"
        labels_dir.mkdir(exist_ok=True)
        
        # å¤„ç†æ©ç ï¼šå¯èƒ½æ˜¯åˆ—è¡¨å½¢å¼æˆ–æ‰¹å¤„ç†å½¢å¼
        seg_masks = None
        if seg_masks_list:
            if len(seg_masks_list) == 1:
                # å¯èƒ½æ˜¯æ‰¹å¤„ç†ï¼Œä¸€æ¬¡è¿”å›æ‰€æœ‰å›¾ç‰‡çš„æ©ç 
                seg_masks = seg_masks_list[0]
            elif len(seg_masks_list) == len(mtdetr_results):
                # æ¯å¼ å›¾ç‰‡å•ç‹¬è¿”å›çš„æ©ç åˆ—è¡¨
                seg_masks = seg_masks_list
            else:
                self.log.emit(f"[è­¦å‘Š] æ©ç æ•°é‡({len(seg_masks_list)})ä¸ç»“æœæ•°é‡({len(mtdetr_results)})ä¸åŒ¹é…")
        
        total_images = len(mtdetr_results)
        for i, (mtdetr_result, person_result) in enumerate(zip(mtdetr_results, person_results)):
            # å‘é€è¿›åº¦ç™¾åˆ†æ¯”
            progress_percent = int((i + 1) / total_images * 100)
            self.progress_percent.emit(progress_percent)
            self.progress.emit(f"æ­£åœ¨ä¿å­˜: {i+1}/{total_images}")
            img = mtdetr_result.orig_img.copy()
            img_h, img_w = img.shape[:2]
            
            # åˆå§‹åŒ–åˆ†æå™¨
            traffic_light_analyzer = TrafficLightAnalyzer()
            
            # æå–å¯é©¾é©¶åŒºåŸŸæ©ç 
            drivable_mask = self._extract_drivable_mask(seg_masks, i, img.shape)
            drivable_area_analyzer = DrivableAreaAnalyzer(drivable_mask)
            
            warnings = []
            traffic_lights_detected = []
            pedestrians_in_drivable = []
            
            # 1. ç»˜åˆ¶ MTDETR åˆ†å‰²æ©ç 
            if seg_masks is not None and i < len(seg_masks):
                try:
                    class_names = {}
                    if hasattr(self.model, 'names') and isinstance(self.model.names, dict):
                        class_names = self.model.names
                    
                    img = self.renderer.draw_all_segmentation_masks(
                        img, seg_masks[i], class_names
                    )
                except Exception as e:
                    self.log.emit(f"[åŒæ¨¡å‹] ç»˜åˆ¶æ©ç å¤±è´¥: {e}")
            
            # 2. ç»˜åˆ¶ MTDETR æ£€æµ‹æ¡†
            if mtdetr_result.boxes is not None:
                for box in mtdetr_result.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    conf = float(box.conf[0])
                    cls_id = int(box.cls[0])
                    
                    class_name = self.renderer.get_class_name(cls_id, mtdetr_result, self.model)
                    self.log.emit(f"[åŒæ¨¡å‹-MTDETR] æ£€æµ‹: ç±»åˆ«ID={cls_id}, ç±»åˆ«åç§°='{class_name}', ç½®ä¿¡åº¦={conf:.2f}")
                    
                    img = self.renderer.draw_detection(
                        img, [x1, y1, x2, y2], cls_id, conf, class_name,
                        show_box=self.params['show_boxes'],
                        show_label=self.params['show_labels'],
                        show_conf=self.params['show_conf']
                    )
            
            # 3. ç»˜åˆ¶å¯é©¾é©¶åŒºåŸŸ
            if drivable_mask is not None and np.sum(drivable_mask) > 0:
                img = drivable_area_analyzer.draw_drivable_zone(img)
            
            # 4. ç»˜åˆ¶ YOLOv10n æ£€æµ‹ç»“æœï¼ˆè¡Œäºº+çº¢ç»¿ç¯ï¼‰
            if person_result.boxes is not None and len(person_result.boxes) > 0:
                for box in person_result.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    conf = float(box.conf[0])
                    cls_id = int(box.cls[0])
                    bbox = [x1, y1, x2, y2]
                    
                    # ä½¿ç”¨ç»Ÿä¸€çš„ç±»åˆ«IDå¸¸é‡
                    if cls_id == YOLO_PERSON_ORIGINAL_ID:  # Person
                        # æ”¹è¿›çš„åˆ¤æ–­é€»è¾‘ï¼šä½¿ç”¨è¡Œäººåº•éƒ¨ä¸­å¿ƒç‚¹å’Œæ‰©å±•çš„å¯é©¾é©¶åŒºåŸŸ
                        # å› ä¸ºåˆ†å‰²æ©ç æœ¬èº«ä¼šæ’é™¤è¡Œäººï¼Œæ‰€ä»¥éœ€è¦æ‰©å±•æ©ç æ¥åˆ¤æ–­è¡Œäººæ˜¯å¦é è¿‘é“è·¯
                        is_in_road = self._is_pedestrian_on_road(bbox, drivable_mask, img_h, img_w)
                        
                        if is_in_road:
                            color = (0, 0, 255)
                            label_text = "Person-OnRoad"  # è‹±æ–‡æ ‡ç­¾
                            pedestrians_in_drivable.append({
                                'bbox': bbox, 'conf': conf, 'in_road': is_in_road
                            })
                            warnings.append(f"è­¦å‘Š: è¡Œäººå‡ºç°åœ¨é“è·¯åŒºåŸŸå†…!")
                        else:
                            color = (0, 255, 0)
                            label_text = "Person"  # è‹±æ–‡æ ‡ç­¾
                        
                        self.log.emit(f"[åŒæ¨¡å‹-YOLOv10n] æ£€æµ‹: è¡Œäºº, ç½®ä¿¡åº¦={conf:.2f}, åœ¨é“è·¯ä¸Š={is_in_road}")
                    
                    elif cls_id == YOLO_TRAFFIC_LIGHT_ORIGINAL_ID:  # Traffic Light
                        # æ£€æµ‹çº¢ç»¿ç¯é¢œè‰²
                        light_color = traffic_light_analyzer.detect_color(img, bbox, debug=False)
                        color_name_cn = traffic_light_analyzer.get_color_name_chinese(light_color)
                        color = traffic_light_analyzer.get_color_bgr(light_color)
                        # ä½¿ç”¨è‹±æ–‡æ ‡ç­¾
                        color_name_en = light_color.capitalize()  # red->Red, green->Green, yellow->Yellow
                        label_text = f"Light-{color_name_en}"
                        
                        traffic_lights_detected.append({
                            'bbox': bbox, 'color': light_color, 'conf': conf
                        })
                        
                        if light_color == 'red':
                            warnings.append(f"æç¤º: æ£€æµ‹åˆ°çº¢ç¯")
                        
                        self.log.emit(f"[åŒæ¨¡å‹-YOLOv10n] æ£€æµ‹: çº¢ç»¿ç¯={color_name_cn}, ç½®ä¿¡åº¦={conf:.2f}")
                    else:
                        color = (255, 0, 255)
                        label_text = f"Unknown-{cls_id}"  # è‹±æ–‡æ ‡ç­¾
                        self.log.emit(f"[åŒæ¨¡å‹-YOLOv10n] æ£€æµ‹: æœªçŸ¥ç±»åˆ«ID={cls_id}, ç½®ä¿¡åº¦={conf:.2f}")
                    
                    # ç»˜åˆ¶
                    if self.params['show_labels']:
                        label = label_text
                        if self.params['show_conf']:
                            label += f" {conf:.2f}"
                    else:
                        label = ""
                    
                    if self.params['show_boxes']:
                        self.renderer.draw_box(img, bbox, color)
                    
                    if label and self.params['show_labels']:
                        self.renderer.draw_label(img, bbox, label, color)
            
            # 5. æ·»åŠ è­¦å‘Šæ¨ªå¹…
            if warnings:
                img = BannerRenderer.draw_warning_banner(img, warnings)
            
            # 6. æ·»åŠ ä¿¡æ¯æ¨ªå¹…
            info_items = []
            if traffic_lights_detected:
                light_info = [f"{item['color']}" for item in traffic_lights_detected]
                info_items.append(f"çº¢ç»¿ç¯: {', '.join(light_info)}")
            if pedestrians_in_drivable:
                info_items.append(f"é“è·¯ä¸Šè¡Œäºº: {len(pedestrians_in_drivable)} äºº")
            
            if info_items:
                img = BannerRenderer.draw_info_banner(img, info_items)
            
            # 7. ä¿å­˜å›¾åƒ
            if self.params['save']:
                filename = Path(mtdetr_result.path).name if hasattr(mtdetr_result, 'path') else f"image_{i}.jpg"
                output_path = output_dir / filename
                cv2.imwrite(str(output_path), img)
                self.log.emit(f"[åŒæ¨¡å‹] ä¿å­˜: {output_path}")
                
                # æ‰“å°æ£€æµ‹æ‘˜è¦
                if warnings:
                    for warning in warnings:
                        self.log.emit(f"  âš ï¸  {warning}")
                if traffic_lights_detected:
                    for tl in traffic_lights_detected:
                        self.log.emit(f"  ğŸš¦ çº¢ç»¿ç¯: {tl['color']} (ç½®ä¿¡åº¦: {tl['conf']:.2f})")
                if pedestrians_in_drivable:
                    self.log.emit(f"  âš ï¸  é“è·¯ä¸Šæ£€æµ‹åˆ° {len(pedestrians_in_drivable)} åè¡Œäºº!")
            
            # 8. ä¿å­˜æ ‡ç­¾æ–‡ä»¶
            if self.params.get('save_txt', True):
                self._save_labels(filename, mtdetr_result, person_result, labels_dir)
    
    def _extract_drivable_mask(self, seg_masks, index, img_shape):
        """æå–å¯é©¾é©¶åŒºåŸŸæ©ç """
        if seg_masks is None:
            return None
        
        # æ ¹æ®æ©ç ç±»å‹æå–å½“å‰å›¾ç‰‡çš„æ©ç 
        if isinstance(seg_masks, list):
            # åˆ—è¡¨å½¢å¼ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€å¼ å›¾ç‰‡çš„æ©ç 
            if index >= len(seg_masks):
                return None
            seg_mask = seg_masks[index]
        else:
            # æ‰¹å¤„ç†å½¢å¼ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆå‡è®¾åŒ…å«æ‰€æœ‰å›¾ç‰‡ï¼‰
            seg_mask = seg_masks
        
        if hasattr(seg_mask, 'cpu'):
            seg_mask_np = seg_mask.cpu().numpy()
        else:
            seg_mask_np = np.array(seg_mask)
        
        # åˆå¹¶æ‰€æœ‰åˆ†å‰²é€šé“ä½œä¸ºå¯é©¾é©¶åŒºåŸŸ
        # å¤„ç†å¤šç§å¯èƒ½çš„å½¢çŠ¶: (C, H, W), (1, C, H, W), (H, W)
        while len(seg_mask_np.shape) > 2:
            # æ²¿ç¬¬ä¸€ä¸ªç»´åº¦å–æœ€å¤§å€¼ï¼Œç›´åˆ°å˜æˆ 2D
            seg_mask_np = seg_mask_np.max(axis=0)
        
        # ç¡®ä¿æ˜¯ 2D ç°åº¦å›¾
        if len(seg_mask_np.shape) == 2:
            drivable_mask = (seg_mask_np * 255).astype(np.uint8)
        else:
            # å¦‚æœè¿˜ä¸æ˜¯ 2Dï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªé€šé“
            drivable_mask = (seg_mask_np[0] * 255).astype(np.uint8)
        
        self.log.emit(f"[å¯é©¾é©¶åŒºåŸŸ] æå–æˆåŠŸï¼Œå½¢çŠ¶: {drivable_mask.shape}")
        
        return drivable_mask
    
    def _is_pedestrian_on_road(self, bbox, drivable_mask, img_h, img_w):
        """
        åˆ¤æ–­è¡Œäººæ˜¯å¦åœ¨é“è·¯ä¸Šï¼ˆæ”¹è¿›ç‰ˆï¼‰
        
        ç­–ç•¥ï¼š
        1. è®¡ç®—è¡Œäººåº•éƒ¨ä¸­å¿ƒç‚¹ï¼ˆè„šçš„ä½ç½®ï¼‰
        2. æ‰©å±•å¯é©¾é©¶åŒºåŸŸæ©ç ï¼ˆå› ä¸ºæ©ç ä¼šæ’é™¤è¡Œäººï¼‰
        3. æ£€æŸ¥è¯¥ç‚¹æ˜¯å¦åœ¨æ‰©å±•åçš„æ©ç é™„è¿‘
        4. ç»“åˆä½ç½®å¯å‘å¼è§„åˆ™ï¼ˆå›¾åƒä¸‹åŠéƒ¨åˆ†æ›´å¯èƒ½æ˜¯é“è·¯ï¼‰
        
        Args:
            bbox: è¡Œäººè¾¹ç•Œæ¡† [x1, y1, x2, y2]
            drivable_mask: å¯é©¾é©¶åŒºåŸŸæ©ç 
            img_h: å›¾åƒé«˜åº¦
            img_w: å›¾åƒå®½åº¦
            
        Returns:
            bool: æ˜¯å¦åœ¨é“è·¯ä¸Š
        """
        x1, y1, x2, y2 = bbox
        
        # è®¡ç®—è¡Œäººåº•éƒ¨ä¸­å¿ƒç‚¹ï¼ˆè„šçš„ä½ç½®ï¼‰
        foot_x = int((x1 + x2) / 2)
        foot_y = int(y2)
        
        # ç­–ç•¥1: åŸºäºä½ç½®çš„å¯å‘å¼è§„åˆ™
        # å¦‚æœè¡Œäººåœ¨å›¾åƒä¸‹åŠéƒ¨åˆ†ï¼ˆé€šå¸¸æ˜¯é“è·¯ï¼‰ï¼Œæ›´å¯èƒ½åœ¨è·¯ä¸Š
        in_lower_half = foot_y > img_h * 0.5
        
        # ç­–ç•¥2: å¦‚æœæœ‰å¯é©¾é©¶åŒºåŸŸæ©ç ï¼Œæ‰©å±•æ©ç å¹¶æ£€æŸ¥
        if drivable_mask is not None and np.sum(drivable_mask) > 0:
            # æ‰©å±•å¯é©¾é©¶åŒºåŸŸæ©ç ï¼ˆè†¨èƒ€æ“ä½œï¼‰
            # è¿™æ ·å¯ä»¥åŒ…å«è¡Œäººå‘¨å›´çš„åŒºåŸŸ
            kernel_size = max(30, int(min(img_h, img_w) * 0.05))  # åŠ¨æ€æ ¸å¤§å°
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
            expanded_mask = cv2.dilate(drivable_mask, kernel, iterations=1)
            
            # æ£€æŸ¥è„šéƒ¨ä½ç½®æ˜¯å¦åœ¨æ‰©å±•åçš„æ©ç å†…
            if 0 <= foot_y < expanded_mask.shape[0] and 0 <= foot_x < expanded_mask.shape[1]:
                on_expanded_road = expanded_mask[foot_y, foot_x] > 0
                
                # ç»¼åˆåˆ¤æ–­ï¼šåœ¨æ‰©å±•æ©ç å†… ä¸” åœ¨å›¾åƒä¸‹åŠéƒ¨åˆ†
                is_on_road = on_expanded_road and in_lower_half
                
                self.log.emit(f"[è¡Œäººåˆ¤æ–­] ä½ç½®=({foot_x}, {foot_y}), æ‰©å±•æ©ç ={on_expanded_road}, "
                             f"ä¸‹åŠéƒ¨={in_lower_half}, æœ€ç»ˆåˆ¤æ–­={is_on_road}")
                
                return is_on_road
        
        # ç­–ç•¥3: å¦‚æœæ²¡æœ‰æ©ç ï¼Œä»…ä½¿ç”¨ä½ç½®è§„åˆ™
        # åœ¨å›¾åƒä¸‹2/3åŒºåŸŸä¸”æ°´å¹³å±…ä¸­åŒºåŸŸçš„è¡Œäººæ›´å¯èƒ½åœ¨è·¯ä¸Š
        in_road_vertical = foot_y > img_h * 0.4
        in_road_horizontal = img_w * 0.2 < foot_x < img_w * 0.8
        
        is_on_road = in_road_vertical and in_road_horizontal
        
        self.log.emit(f"[è¡Œäººåˆ¤æ–­-æ— æ©ç ] ä½ç½®=({foot_x}, {foot_y}), "
                     f"å‚ç›´={in_road_vertical}, æ°´å¹³={in_road_horizontal}, ç»“æœ={is_on_road}")
        
        return is_on_road
    
    def _save_labels(self, filename, mtdetr_result, person_result, labels_dir):
        """ä¿å­˜æ ‡ç­¾æ–‡ä»¶"""
        label_filename = Path(filename).stem + '.txt'
        label_path = labels_dir / label_filename
        
        with open(label_path, 'w') as f:
            # å†™å…¥ MTDETR çš„æ£€æµ‹
            if mtdetr_result.boxes is not None:
                for box in mtdetr_result.boxes:
                    xywhn = box.xywhn[0]
                    cls = int(box.cls[0])
                    conf = float(box.conf[0])
                    f.write(f"{cls} {xywhn[0]} {xywhn[1]} {xywhn[2]} {xywhn[3]} {conf}\n")
            
            # å†™å…¥ YOLOv10n çš„æ£€æµ‹ï¼ˆä½¿ç”¨ç‰¹æ®Šç±»åˆ«IDï¼‰
            if person_result.boxes is not None:
                for box in person_result.boxes:
                    xywhn = box.xywhn[0]
                    conf = float(box.conf[0])
                    cls_id = int(box.cls[0])
                    
                    # ä½¿ç”¨ç»Ÿä¸€çš„ç±»åˆ«IDå¸¸é‡
                    if cls_id == YOLO_PERSON_ORIGINAL_ID:
                        special_id = YOLO_PERSON_CLASS_ID
                    elif cls_id == YOLO_TRAFFIC_LIGHT_ORIGINAL_ID:
                        special_id = YOLO_TRAFFIC_LIGHT_CLASS_ID
                    else:
                        special_id = YOLO_OTHER_CLASS_ID
                    
                    f.write(f"{special_id} {xywhn[0]} {xywhn[1]} {xywhn[2]} {xywhn[3]} {conf}\n")
